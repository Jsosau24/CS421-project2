# CS421-project2

*To look at the code I wrote look at the project2 branch*

In this assignment, I applied the same Word2Vec model we saw in class to source code to create Python2Vec.  I created a Jupyter Notebook where I first went through the repositories and separated the python files from the rest and cleaned the unused files. After that I created an Ngram program where I created tokens for every word and used a similar Ngram model to the one we saw in class. After that I modified the code to tokenize the python code in order to get an array of tokenized words per line of code. Then using the Gensim Word2Vec model I trained it in order to obtain the most similar word.
